Meta:
  num_objs: 2

Environment:
  dimensions: [18, 10]
  ep_length: 10  # episode length
  timestep_penalty: 0
  global_reward_mode: "Aggregated"  # Options: "Aggregated", "Final"
  local_reward_mode: "exponential" # Options: inverse_distance, exponential
  local_reward_kneecap: 10.0 # Distance from POI at which local reward is exactly 1 (higher if closer)
  local_reward_temp: 2 # higher, the smoother the reward gradient (irrelevant if reward mode is inverse_distnace)
  observation_mode: 'density' # Options: 'count' or 'density'
  poi_obs_temp: 2 # Temp if density observation mode
  agent_obs_temp: 2 # Temp if density observation mode
  include_location_in_obs: False # Should the agent know its own position?

  # Objectives must start from 0.
  pois:
    - obj: 0
      location: [2, 1]
      radius: 0.5
      coupling: 1
      obs_window: [0, 90]
      reward: 1
      repeat: False
    - obj: 1
      location: [4, 1]
      radius: 0.5
      coupling: 1
      obs_window: [0, 90]
      reward: 1
      repeat: False
    - obj: 0
      location: [2, 3]
      radius: 0.5
      coupling: 1
      obs_window: [0, 90]
      reward: 1
      repeat: False
    - obj: 1
      location: [4, 3]
      radius: 0.5
      coupling: 1
      obs_window: [0, 90]
      reward: 1
      repeat: False
    - obj: 0
      location: [2, 5]
      radius: 0.5
      coupling: 1
      obs_window: [0, 90]
      reward: 1
      repeat: False
    - obj: 1
      location: [4, 5]
      radius: 0.5
      coupling: 1
      obs_window: [0, 90]
      reward: 1
      repeat: False
    - obj: 0
      location: [2, 7]
      radius: 0.5
      coupling: 1
      obs_window: [0, 90]
      reward: 1
      repeat: False
    - obj: 1
      location: [4, 7]
      radius: 0.5
      coupling: 1
      obs_window: [0, 90]
      reward: 1
      repeat: False
    - obj: 0
      location: [2, 9]
      radius: 0.5
      coupling: 1
      obs_window: [0, 90]
      reward: 1
      repeat: False
    - obj: 1
      location: [4, 9]
      radius: 0.5
      coupling: 1
      obs_window: [0, 90]
      reward: 1
      repeat: False
    - obj: 0
      location: [2, 11]
      radius: 0.5
      coupling: 1
      obs_window: [0, 90]
      reward: 1
      repeat: False
    - obj: 1
      location: [4, 11]
      radius: 0.5
      coupling: 1
      obs_window: [0, 90]
      reward: 1
      repeat: False
    - obj: 0
      location: [2, 13]
      radius: 0.5
      coupling: 1
      obs_window: [0, 90]
      reward: 1
      repeat: False
    - obj: 1
      location: [4, 13]
      radius: 0.5
      coupling: 1
      obs_window: [0, 90]
      reward: 1
      repeat: False
    - obj: 0
      location: [2, 15]
      radius: 0.5
      coupling: 1
      obs_window: [0, 90]
      reward: 1
      repeat: False
    - obj: 1
      location: [4, 15]
      radius: 0.5
      coupling: 1
      obs_window: [0, 90]
      reward: 1
      repeat: False
    
    - obj: 0
      location: [14, 1]
      radius: 0.5
      coupling: 1
      obs_window: [0, 90]
      reward: 1
      repeat: False
    - obj: 1
      location: [16, 1]
      radius: 0.5
      coupling: 1
      obs_window: [0, 90]
      reward: 1
      repeat: False
    - obj: 0
      location: [14, 3]
      radius: 0.5
      coupling: 1
      obs_window: [0, 90]
      reward: 1
      repeat: False
    - obj: 1
      location: [16, 3]
      radius: 0.5
      coupling: 1
      obs_window: [0, 90]
      reward: 1
      repeat: False
    - obj: 0
      location: [14, 5]
      radius: 0.5
      coupling: 1
      obs_window: [0, 90]
      reward: 1
      repeat: False
    - obj: 1
      location: [16, 5]
      radius: 0.5
      coupling: 1
      obs_window: [0, 90]
      reward: 1
      repeat: False
    - obj: 0
      location: [14, 7]
      radius: 0.5
      coupling: 1
      obs_window: [0, 90]
      reward: 1
      repeat: False
    - obj: 1
      location: [16, 7]
      radius: 0.5
      coupling: 1
      obs_window: [0, 90]
      reward: 1
      repeat: False
    - obj: 0
      location: [14, 9]
      radius: 0.5
      coupling: 1
      obs_window: [0, 90]
      reward: 1
      repeat: False
    - obj: 1
      location: [16, 9]
      radius: 0.5
      coupling: 1
      obs_window: [0, 90]
      reward: 1
      repeat: False
    - obj: 0
      location: [14, 11]
      radius: 0.5
      coupling: 1
      obs_window: [0, 90]
      reward: 1
      repeat: False
    - obj: 1
      location: [16, 11]
      radius: 0.5
      coupling: 1
      obs_window: [0, 90]
      reward: 1
      repeat: False
    - obj: 0
      location: [14, 13]
      radius: 0.5
      coupling: 1
      obs_window: [0, 90]
      reward: 1
      repeat: False
    - obj: 1
      location: [16, 13]
      radius: 0.5
      coupling: 1
      obs_window: [0, 90]
      reward: 1
      repeat: False
    - obj: 0
      location: [14, 15]
      radius: 0.5
      coupling: 1
      obs_window: [0, 90]
      reward: 1
      repeat: False
    - obj: 1
      location: [16, 15]
      radius: 0.5
      coupling: 1
      obs_window: [0, 90]
      reward: 1
      repeat: False


Agents:
  starting_locs: [[3, 0], [15, 0]] #Remember, the dimensionality of this influences the state input size. Length determines team size!!!
  num_sensors: [4, 4] # Remember, these many sensors for detecting pois + these many sensors for detecting other agents
  observation_radii: [10, 10]
  max_step_sizes: [1, 1]